{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38164bittorchcondadd711ca68ad04861aabbde1fbd726c82",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "d412cf0cc95275da7f3e5a2cde727869a6beaae6991f4cbb39a087a6b0868edc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "# Retrieve data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_data(stock: str, start: datetime = None, end: datetime = None):\n",
    "    beg = datetime(1970, 1, 1)\n",
    "    if start == None:\n",
    "        start = beg\n",
    "    if end == None:\n",
    "        end = datetime.now()\n",
    "\n",
    "    sdate = int((start - beg).total_seconds())\n",
    "    edate = int((end - beg).total_seconds())\n",
    "\n",
    "    url = f'https://query1.finance.yahoo.com/v7/finance/download/{stock}?period1={sdate}&period2={edate}&interval=1d&events=history&includeAdjustedClose=true'\n",
    "    return pd.read_csv(url, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "msft = get_ticker_data('MSFT')\n",
    "msft['Date'] = msft['Date'].apply(pd.to_datetime)\n",
    "msft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(msft, x='Date', y=['Close'], title='MSFT Stock Price')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_all = msft['Close'].values\n",
    "msft_all"
   ]
  },
  {
   "source": [
    "# Split\n",
    "Create train / test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = len(msft_all)\n",
    "test_sz = math.floor(.1 * sz)\n",
    "sz, test_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = msft_all[:-test_sz]\n",
    "test_data = msft_all[-test_sz:]\n",
    "len(train_data)+len(test_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msmin, msmax = train_data.min(), train_data.max()\n",
    "print(f'Min: {msmin}, Max: {msmax}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_scaled = (train_data - msmin) / (msmax - msmin)\n",
    "fig = px.line(train_data_scaled, title='MSFT Stock Price (Scaled)')\n",
    "fig.show()"
   ]
  },
  {
   "source": [
    "# Create Series Generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(seq_data: np.array, sz: int = 3):\n",
    "    for i in range(len(seq_data) - sz):\n",
    "        yield seq_data[i:i+sz], seq_data[i+sz:i+sz+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(train_data_scaled) - 100), len(train_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tries = 5\n",
    "for x, y in gen_dataset(train_data_scaled):\n",
    "    print(x, y)\n",
    "    tries -= 1\n",
    "    if tries == 0:\n",
    "        break\n",
    "print(train_data_scaled[0:10], train_data_scaled[11:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dataset(train_data_scaled, 100)\n",
    "np.fromiter(gen_dataset(train_data_scaled, 100), dtype=float)"
   ]
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "output_dim = 1\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn) = self.gru(x, (h0.detach()))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    y_train_pred = model(x_train)\n",
    "    loss = criterion(y_train_pred, y_train)\n",
    "    print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = torch.from_numpy(np.array([float(i) for i in range(5)]))\n",
    "seq1 = torch.from_numpy(np.array([[k for k in range(3)] for i in range(5)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, str(Path('..').resolve()))\n",
    "from tlaloc.data import SequenceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}